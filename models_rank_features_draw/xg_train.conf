[xg_conf]
# DO NOT DELET OR ADD AND PARAMETERS HERE. IF YOU HAVE TO, PLEASE REVISE THE CODE: xg_train.py

# General Parameters, see comment for each definition
# choose the booster, can be gbtree or gblinear
booster = gbtree
# choose logistic regression loss function for binary classification
objective = binary:logistic
# Do not show the detailed information[1 Yes, 0 NO]
silent = 0

# Tree Booster Parameters
# step size shrinkage
eta = 1.0
# minimum loss reduction required to make a further partition
gamma = 1.0
# minimum sum of instance weight(hessian) needed in a child
min_child_weight = 1
# maximum depth of a tree
max_depth = 20

# Task Parameters
# the number of round to do boosting
num_round = 10
# 0 means do not save any model except the final round model
save_period = 0
# The path of training data
# Is the training data xg format? [1 Yes, 0 No]
#xgmat = 0
#data = Data/NN_train.txt
#label = Data/NNAI_train.txt

train_path = ../datas/version2/features-201707/train_flags_normalized.csv
ranks_dir = version2_features_201707
# eval: show the train error in each round[0 no]
eval = 1
#  MultiThread
nthread = 10
